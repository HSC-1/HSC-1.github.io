---
layout: post
title:  "재미있는 모델 소개"
date:   2021-03-16
excerpt: "mono2depth: 일반 이미지로 깊이감을 알수있다."
tag:
- AI
- pytorch
categories: AI
comments: true
---
# mono2depth
segmentation의 문제 개선안으로 두개의 카메라로 찍은 입체감 있는 사진을 사용한다는 글을 봐서 그러면 원래 있는 사진들은 못쓰는 게 너무 아쉬워서 그런 것이 있는지 검색을 하다가 sturct2depth을 보게 되었습니다.  하지만 tensorflow github model에 주소가 404에러가 나고 다른 포크된사람들 것 보니 버전1를 사용하고 2를 지원하지 않아 호환성 문제로 참고를 못해 mono2depth를 보게 되어 한 번 찍먹하게 되었습니다.  
tensorflow를 배워 tensorflow위주로 찾게 되었는데 이번 모델 튜토리얼은 pytorch로 작성되어 추가적으로 모델학습이나 구조변경은 하지 못하였는데 파이토치와 텐서플로의 오래된 모델 찾거나 구현하는데 편한 것이 파이토치란 것을 알게 되어 파이토치에 대해서도 공부하려고 합니다.  
이번에는 모델에 어떤 레이어가 쓰인 것보다 훈련된 가중치와 모델만 가져와 썼을 때 오래된 모델로 알고 있었는데 생각보다 신기해서 소개하겠습니다.
기본으로 이미 어느정도 학습된 가중치를 가져와 사용하였습니다. 
<!-- ![](https://raw.githubusercontent.com/HSC-1/HSC-1.github.io/main/_posts/image/hong.png)  
![](https://raw.githubusercontent.com/HSC-1/HSC-1.github.io/main/_posts/image/runway.png) -->
<img src="https://raw.githubusercontent.com/HSC-1/HSC-1.github.io/main/_posts/image/hong.png" width = "400px"></img>
<img src="https://raw.githubusercontent.com/HSC-1/HSC-1.github.io/main/_posts/image/runway.png" width = "400px"></img>  
이미지마다 차이가 많이 나지만 길거리 사진이면 어느정도 깊이감을 느낄 수 있다는 것이 재미가 있어 저것을 활용하여 자율주행 같은 것에 활용도도 좋아 보였다. struct2depth 같은 경우에는 사무공간에 자율주행 로봇을 배치한 것도 있었습니다.[링크](https://sites.google.com/view/struct2depth)





[깃허브 레포](https://github.com/HSC-1/aiffel_achieve/blob/master/(E10)segmentation.ipynb)에서 코드로 확인 할 수 있습니다.  
참고 링크

[monodepth](https://github.com/nianticlabs/monodepth2)